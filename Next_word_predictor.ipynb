{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f502b66-d8c8-434e-9043-975e91633ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "Identifying the most likely word to follow a given string of words is the basic goal of the Natural Language Processing (NLP) task of “next word prediction.” This predictive skill is essential in various applications, including text auto-completion, speech recognition, and machine translation. Deep learning approaches have transformed NLP by attaining remarkable success in various language-related tasks, such as next-word prediction.\n",
    "\n",
    "Deep learning models are excellent at identifying complex dependencies and patterns in sequential data, which makes them suitable for challenges requiring the prediction of the next word. These models may successfully describe the context and make precise predictions by utilizing recurrent neural networks (RNNs) and their variations, such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU).\n",
    "\n",
    "There are many benefits to being able to correctly predict the following word in a given situation. Offering relevant and coherent word suggestions improves the user experience in auto-completion systems.\n",
    "\n",
    "Model Architecture\n",
    "The model architecture is a critical component in building an effective next-word prediction system using deep learning in NLP.\n",
    "One common approach is to utilize recurrent neural networks (RNNs) or their variants, such as Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU). These architectures are specifically designed to capture sequential dependencies in the input text, enabling accurate predictions of the next word.\n",
    "Recurrent Neural Networks (RNNs): Recurrent Neural Networks are a class of neural networks that can process sequential data by maintaining hidden states that capture the context and information from previous inputs. RNNs have loops within their architecture that allow them to store and propagate information through time.\n",
    "Long Short-Term Memory (LSTM): LSTM is a specialized variant of RNNs that overcomes the limitations of traditional RNNs, such as the vanishing gradient problem. LSTM introduces a memory cell that allows the network to selectively store and retrieve information over long sequences, making it particularly effective in modeling long-term dependencies.\n",
    "Gated Recurrent Unit (GRU): GRU is another variant of RNNs that simplifies the architecture of LSTM by merging the cell state and hidden state into a single state vector. GRU also introduces gating mechanisms to control the flow of information, making it computationally efficient while still capturing long-term dependencies.\n",
    "Model Architecture for Next Word Prediction\n",
    "The model architecture for next-word prediction typically consists of the following components:\n",
    "Embedding Layer: The word embeddings, often referred to as distributed representations of words, are learned by the embedding layer. It captures semantic and contextual information by mapping every word in the lexicon to a dense vector representation. The model can be trained to change these embeddings as trainable parameters.\n",
    "Recurrent Layers: The recurrent layers, like LSTM or GRU, process the input word embeddings in sequential order and keep hidden states that record the sequential data. The model can learn the contextual connections between words and their placements in the sequence thanks to these layers.\n",
    "Dense Layers: One or more dense layers are then added after the recurrent layers to convert the learned features into the appropriate output format. When predicting the next word, the dense layers translate the hidden representations to a probability distribution across the vocabulary, indicating the likelihood that each word will be the following word.\n",
    "Training and Optimization\n",
    "The model is trained using a large corpus of text data, where the input sequences are paired with their corresponding target word. The training process involves optimizing the model’s parameters by minimizing a suitable loss function, such as categorical cross-entropy. The optimization is typically performed using an optimization algorithm like Adam or Stochastic Gradient Descent (SGD).\n",
    "Inference and Prediction\n",
    "The model can be used to predict the next word once it has been trained. The trained model receives an input of a list of words, processes it through the learned architecture, and outputs a probability distribution across the vocabulary. The anticipated next word is then chosen as the one with the highest likelihood.\n",
    "We can create reliable and accurate next-word prediction models for NLP by combining the strength of recurrent neural networks, such as LSTM or GRU, with the right training and optimization methods. The model design successfully captures the text’s sequential dependencies, enabling the system to produce fluent and contextually relevant predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b71545-293d-4b08-a2bf-6e00862e66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa515c2-982b-4be2-8696-b4a5d6fbccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880e3b8c-f254-4abe-80f8-6d0b36220cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4456cc-0baf-4955-972c-4ac458615e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c6e2ed-0e96-427a-89dc-4953c878970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90df3fa-6005-4b95-8d0a-55ec1330f32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words=len(tokenizer.word_index)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57d36d6-a2fc-4842-a80a-390b4c5dc3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'word': 2,\n",
       " 'and': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'a': 6,\n",
       " 'in': 7,\n",
       " 'recurrent': 8,\n",
       " 'next': 9,\n",
       " 'model': 10,\n",
       " 'is': 11,\n",
       " 'as': 12,\n",
       " 'prediction': 13,\n",
       " 'by': 14,\n",
       " 'lstm': 15,\n",
       " 'that': 16,\n",
       " 'are': 17,\n",
       " 'rnns': 18,\n",
       " 'gru': 19,\n",
       " 'architecture': 20,\n",
       " 'layers': 21,\n",
       " 'such': 22,\n",
       " 'sequential': 23,\n",
       " 'neural': 24,\n",
       " 'networks': 25,\n",
       " 'long': 26,\n",
       " 'or': 27,\n",
       " 'dependencies': 28,\n",
       " 'their': 29,\n",
       " 'term': 30,\n",
       " 'can': 31,\n",
       " 'information': 32,\n",
       " 'it': 33,\n",
       " 'words': 34,\n",
       " 'nlp': 35,\n",
       " 'data': 36,\n",
       " 'for': 37,\n",
       " 'these': 38,\n",
       " 'memory': 39,\n",
       " 'input': 40,\n",
       " 'hidden': 41,\n",
       " 'dense': 42,\n",
       " 'trained': 43,\n",
       " 'optimization': 44,\n",
       " 'text': 45,\n",
       " 'deep': 46,\n",
       " 'learning': 47,\n",
       " 'models': 48,\n",
       " 'predictions': 49,\n",
       " 'short': 50,\n",
       " 'gated': 51,\n",
       " 'unit': 52,\n",
       " 'following': 53,\n",
       " 'an': 54,\n",
       " 'using': 55,\n",
       " 'one': 56,\n",
       " 'process': 57,\n",
       " 'state': 58,\n",
       " 'embeddings': 59,\n",
       " 'learned': 60,\n",
       " 'be': 61,\n",
       " 'training': 62,\n",
       " 'with': 63,\n",
       " 'identifying': 64,\n",
       " 'given': 65,\n",
       " 'language': 66,\n",
       " 'various': 67,\n",
       " 'auto': 68,\n",
       " 'completion': 69,\n",
       " 'have': 70,\n",
       " 'them': 71,\n",
       " 'suitable': 72,\n",
       " 'successfully': 73,\n",
       " 'context': 74,\n",
       " 'predict': 75,\n",
       " 'relevant': 76,\n",
       " 'effective': 77,\n",
       " 'system': 78,\n",
       " 'capture': 79,\n",
       " 'enabling': 80,\n",
       " 'accurate': 81,\n",
       " 'states': 82,\n",
       " 'store': 83,\n",
       " 'through': 84,\n",
       " 'variant': 85,\n",
       " 'gradient': 86,\n",
       " 'introduces': 87,\n",
       " 'cell': 88,\n",
       " 'sequences': 89,\n",
       " 'making': 90,\n",
       " 'into': 91,\n",
       " 'vector': 92,\n",
       " 'typically': 93,\n",
       " 'embedding': 94,\n",
       " 'layer': 95,\n",
       " 'representations': 96,\n",
       " 'captures': 97,\n",
       " 'contextual': 98,\n",
       " 'parameters': 99,\n",
       " 'like': 100,\n",
       " 'then': 101,\n",
       " 'probability': 102,\n",
       " 'distribution': 103,\n",
       " 'across': 104,\n",
       " 'vocabulary': 105,\n",
       " 'likelihood': 106,\n",
       " 'most': 107,\n",
       " 'likely': 108,\n",
       " 'follow': 109,\n",
       " 'string': 110,\n",
       " 'basic': 111,\n",
       " 'goal': 112,\n",
       " 'natural': 113,\n",
       " 'processing': 114,\n",
       " 'task': 115,\n",
       " '“next': 116,\n",
       " '”': 117,\n",
       " 'this': 118,\n",
       " 'predictive': 119,\n",
       " 'skill': 120,\n",
       " 'essential': 121,\n",
       " 'applications': 122,\n",
       " 'including': 123,\n",
       " 'speech': 124,\n",
       " 'recognition': 125,\n",
       " 'machine': 126,\n",
       " 'translation': 127,\n",
       " 'approaches': 128,\n",
       " 'transformed': 129,\n",
       " 'attaining': 130,\n",
       " 'remarkable': 131,\n",
       " 'success': 132,\n",
       " 'related': 133,\n",
       " 'tasks': 134,\n",
       " 'excellent': 135,\n",
       " 'at': 136,\n",
       " 'complex': 137,\n",
       " 'patterns': 138,\n",
       " 'which': 139,\n",
       " 'makes': 140,\n",
       " 'challenges': 141,\n",
       " 'requiring': 142,\n",
       " 'may': 143,\n",
       " 'describe': 144,\n",
       " 'make': 145,\n",
       " 'precise': 146,\n",
       " 'utilizing': 147,\n",
       " 'variations': 148,\n",
       " 'there': 149,\n",
       " 'many': 150,\n",
       " 'benefits': 151,\n",
       " 'being': 152,\n",
       " 'able': 153,\n",
       " 'correctly': 154,\n",
       " 'situation': 155,\n",
       " 'offering': 156,\n",
       " 'coherent': 157,\n",
       " 'suggestions': 158,\n",
       " 'improves': 159,\n",
       " 'user': 160,\n",
       " 'experience': 161,\n",
       " 'systems': 162,\n",
       " 'critical': 163,\n",
       " 'component': 164,\n",
       " 'building': 165,\n",
       " 'common': 166,\n",
       " 'approach': 167,\n",
       " 'utilize': 168,\n",
       " 'variants': 169,\n",
       " 'architectures': 170,\n",
       " 'specifically': 171,\n",
       " 'designed': 172,\n",
       " 'class': 173,\n",
       " 'maintaining': 174,\n",
       " 'from': 175,\n",
       " 'previous': 176,\n",
       " 'inputs': 177,\n",
       " 'loops': 178,\n",
       " 'within': 179,\n",
       " 'allow': 180,\n",
       " 'propagate': 181,\n",
       " 'time': 182,\n",
       " 'specialized': 183,\n",
       " 'overcomes': 184,\n",
       " 'limitations': 185,\n",
       " 'traditional': 186,\n",
       " 'vanishing': 187,\n",
       " 'problem': 188,\n",
       " 'allows': 189,\n",
       " 'network': 190,\n",
       " 'selectively': 191,\n",
       " 'retrieve': 192,\n",
       " 'over': 193,\n",
       " 'particularly': 194,\n",
       " 'modeling': 195,\n",
       " 'another': 196,\n",
       " 'simplifies': 197,\n",
       " 'merging': 198,\n",
       " 'single': 199,\n",
       " 'also': 200,\n",
       " 'gating': 201,\n",
       " 'mechanisms': 202,\n",
       " 'control': 203,\n",
       " 'flow': 204,\n",
       " 'computationally': 205,\n",
       " 'efficient': 206,\n",
       " 'while': 207,\n",
       " 'still': 208,\n",
       " 'capturing': 209,\n",
       " 'consists': 210,\n",
       " 'components': 211,\n",
       " 'often': 212,\n",
       " 'referred': 213,\n",
       " 'distributed': 214,\n",
       " 'semantic': 215,\n",
       " 'mapping': 216,\n",
       " 'every': 217,\n",
       " 'lexicon': 218,\n",
       " 'representation': 219,\n",
       " 'change': 220,\n",
       " 'trainable': 221,\n",
       " 'order': 222,\n",
       " 'keep': 223,\n",
       " 'record': 224,\n",
       " 'learn': 225,\n",
       " 'connections': 226,\n",
       " 'between': 227,\n",
       " 'placements': 228,\n",
       " 'sequence': 229,\n",
       " 'thanks': 230,\n",
       " 'more': 231,\n",
       " 'added': 232,\n",
       " 'after': 233,\n",
       " 'convert': 234,\n",
       " 'features': 235,\n",
       " 'appropriate': 236,\n",
       " 'output': 237,\n",
       " 'format': 238,\n",
       " 'when': 239,\n",
       " 'predicting': 240,\n",
       " 'translate': 241,\n",
       " 'indicating': 242,\n",
       " 'each': 243,\n",
       " 'will': 244,\n",
       " 'large': 245,\n",
       " 'corpus': 246,\n",
       " 'where': 247,\n",
       " 'paired': 248,\n",
       " 'corresponding': 249,\n",
       " 'target': 250,\n",
       " 'involves': 251,\n",
       " 'optimizing': 252,\n",
       " 'model’s': 253,\n",
       " 'minimizing': 254,\n",
       " 'loss': 255,\n",
       " 'function': 256,\n",
       " 'categorical': 257,\n",
       " 'cross': 258,\n",
       " 'entropy': 259,\n",
       " 'performed': 260,\n",
       " 'algorithm': 261,\n",
       " 'adam': 262,\n",
       " 'stochastic': 263,\n",
       " 'descent': 264,\n",
       " 'sgd': 265,\n",
       " 'inference': 266,\n",
       " 'used': 267,\n",
       " 'once': 268,\n",
       " 'has': 269,\n",
       " 'been': 270,\n",
       " 'receives': 271,\n",
       " 'list': 272,\n",
       " 'processes': 273,\n",
       " 'outputs': 274,\n",
       " 'anticipated': 275,\n",
       " 'chosen': 276,\n",
       " 'highest': 277,\n",
       " 'we': 278,\n",
       " 'create': 279,\n",
       " 'reliable': 280,\n",
       " 'combining': 281,\n",
       " 'strength': 282,\n",
       " 'right': 283,\n",
       " 'methods': 284,\n",
       " 'design': 285,\n",
       " 'text’s': 286,\n",
       " 'produce': 287,\n",
       " 'fluent': 288,\n",
       " 'contextually': 289}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f3bbd93-1ec4-4834-87a4-1f10736ddc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs=[]\n",
    "for sentence in text.split('\\n'):\n",
    "    tokenize_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1,len(tokenize_sentence)):\n",
    "        input_seqs.append(tokenize_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68397100-c4e8-46a1-a004-372003f31d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b8d9f2b-6faf-49dd-b092-010517640bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=max([len(x) for x in input_seqs])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080b4180-5f7d-4ee3-95b9-3888af25fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_input_seqs=pad_sequences(input_seqs, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d3410f-495f-412a-bd68-82e12930276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=padded_input_seqs[:, :-1]\n",
    "y=padded_input_seqs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80bec08b-c2d6-4e9e-9540-b486f1c3989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8e5647-12af-44ae-985d-2425d2c7d42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687, 64), (687,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e551ee1-876f-46d4-b69e-b1052ce00c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y=to_categorical(y, num_classes=unique_words+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba417d64-9178-4ca0-a0aa-bb6299189737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ae50c5b-c9b0-4a07-b87a-274332d635e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700ad05a-b2de-40d0-90af-390f6b212893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kasiv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Embedding(unique_words+1, 100, input_length=x.shape[1]))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(unique_words+1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e2e4f7b-ea0a-4449-a751-a6ef3a81ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kasiv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " model.compile(\n",
    "     loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "107c1ba8-f3b8-4491-9a6a-9c44292220b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36fd343-03e9-4959-866b-d45842fb488a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 290)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04df0843-1a60-47c7-a7fd-94b9db263bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 64, 100)           29000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 290)               43790     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 223390 (872.62 KB)\n",
      "Trainable params: 223390 (872.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2614466-8ff5-4940-97da-7764bfbe6c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 5.0615 - accuracy: 0.0771\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 4.9995 - accuracy: 0.0771\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 1s 66ms/step - loss: 4.9147 - accuracy: 0.0771\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 1s 68ms/step - loss: 4.7992 - accuracy: 0.0830\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 2s 69ms/step - loss: 4.6304 - accuracy: 0.0830\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 2s 69ms/step - loss: 4.4367 - accuracy: 0.1208\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 4.2102 - accuracy: 0.1441\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 3.9793 - accuracy: 0.1761\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 3.7271 - accuracy: 0.2154\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 3.4708 - accuracy: 0.2416\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 3.2577 - accuracy: 0.2795\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 3.0156 - accuracy: 0.3275\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 2.8124 - accuracy: 0.3450\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 2.5963 - accuracy: 0.4017\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 2.4032 - accuracy: 0.4410\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 2.2250 - accuracy: 0.4993\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 2.0471 - accuracy: 0.5619\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 1.8949 - accuracy: 0.6041\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 1.7533 - accuracy: 0.6419\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 1.6067 - accuracy: 0.7089\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 2s 76ms/step - loss: 1.4833 - accuracy: 0.7467\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 1.3641 - accuracy: 0.7962\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 1.2542 - accuracy: 0.8326\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 1.1660 - accuracy: 0.8603\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 1.0687 - accuracy: 0.8879\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.9885 - accuracy: 0.9025\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.9128 - accuracy: 0.9229\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 0.8489 - accuracy: 0.9360\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 0.7854 - accuracy: 0.9432\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.7239 - accuracy: 0.9636\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.6719 - accuracy: 0.9636\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.6247 - accuracy: 0.9665\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.5807 - accuracy: 0.9782\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.5385 - accuracy: 0.9811\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5057 - accuracy: 0.9782\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.4700 - accuracy: 0.9811\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.4379 - accuracy: 0.9854\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.4084 - accuracy: 0.9884\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3815 - accuracy: 0.9854\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3583 - accuracy: 0.9913\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 2s 84ms/step - loss: 0.3360 - accuracy: 0.9927\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.3161 - accuracy: 0.9898\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2969 - accuracy: 0.9898\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 0.2811 - accuracy: 0.9913\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.2661 - accuracy: 0.9927\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 2s 76ms/step - loss: 0.2506 - accuracy: 0.9927\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.2396 - accuracy: 0.9913\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 0.2274 - accuracy: 0.9913\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 0.2138 - accuracy: 0.9898\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 0.2041 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x179adb6db50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "964e9ce2-7c8d-4365-8ab0-2c1cac54732e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Identifying the\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Identifying the most\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Identifying the most likely\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Identifying the most likely word\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Identifying the most likely word to\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text=\"Identifying\"\n",
    "for i in range(5):\n",
    "    tokenized=tokenizer.texts_to_sequences([text])[0]\n",
    "    \n",
    "\n",
    "    padded=pad_sequences([tokenized], maxlen=max_len-1, padding='pre')\n",
    "    \n",
    "    pos=np.argmax(model.predict(padded))\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index==pos:\n",
    "            text=text +\" \"+ word\n",
    "            print(text)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069310b-9009-4c19-8461-44dd3b81b4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506ff83-ce18-444f-9662-327ca9fe90da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfae063-9166-48ea-bdd3-48b9878b4801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
